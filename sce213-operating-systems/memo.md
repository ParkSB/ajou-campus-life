# 운영체제

## Introduction to Operating Systems

### System Calls

- 폰 노이만 구조, 모드 얘기, privileged instructions.
- 인터럽트:
  - 인터럽트는 하드웨어 장치가 만드는 신호. 비동기적으로 발생.
  - 현대 컴퓨터는 인터럽트 주도 방식으로 동작. 인터럽트가 발생하면 모드가 전환될 수 있음.
  - 익셉션(exception):
    - 소프트웨어가 인스트럭션을 실행하다가 만드는 신호.
    - 동기적으로 발생. CPU가 인스트럭션을 실행할 때만 일어남.
    - 의도를 갖고 일으킨 익셉션은 트랩(trap).
    - 예상치 못한 익셉션은 폴트(fault)
- 시스템 콜:
  - 식당에서 벨 누르면 주방에서 커널모드로 일하던 사장님이 홀에 나와서 유저모드로 전환하심.
  - OS가 서비스에게 제공하는 프로그래밍 인터페이스:
    - Win32 API for Windows, POSIX API for POSIX-based systems, Java API for JVM 등.
    - OS가 제공하는 서비스는 프로그램 실행, 파일 시스템, IO, 통신, 에러 감지 등.
  - man 페이지에 다 나와있음. 궁금하면 그냥 무조건 man 페이지보세요.
  - 리눅스에 시스템 콜이 몇 개나 있을 것 같아요? 350개 정도.
  - 저는 시스템 콜 써본 적이 없는데용? 사실 다 쓰고 있음.
  - `printf`도 시스템 콜인가요? 그건 표준 C 라이브러리. 라이브러리가 `write` 시스템 콜을 호출함.
- 컴퓨터 켜면 무슨 일이 일어나나요? Bootstrap program > Bootloader > Kernel phase 1 > Kernel phase 2

### OS Structures

- 과제 질문이 많이 들어옴. 윈도우즈 시스템에서 하지 마세용.
- 운영체제를 새로 하나 만들다고 생각해보죠:
  - 절대적인 답도 없고 최고의 방법도 없음. 대충 이렇게 했더니 성공적인 운영체제가 만들어지더라.
  - 그래서 우리는 운영체제가 일반적으로 어떻게 되어있고, 성공한 운영체제는 어떻더라 같은 얘기만 할거임.
  - 기본적으로 요구사항과 목적을 달성할 수 있어야. 스펙을 잘 정의해야 한다.
    - 어떤 하드웨어로, 어떤 종류의 시스템에서, 어떤 환경에서, ...
    - 사용자: 사용하기 편하고 배우기 쉬워야, 믿을 수 있어야, 안전해야, 빨라야.
    - 시스템: 설계하기 쉬워야, 구현하기 쉬워야, 유지보수가 쉬워야, 유연해야, 오류없어야, 효율적이어야.
  - 어떻게 구현할까?
    - 초기 운영체제는 어셈블리로 작성. 그 이후로는 Algol, PL/1 사용.
    - 오늘 날에는 굉장히 많은 시스템이 C/C++로 작성됨. 시스템을 하나의 언어만으로 구현하지 않음.
    - 리눅스는 대부분 C로 작성됨. 토발즈가 C++ 안 좋아함. 저도 C++ 안 좋아해요. 언어가 지저분해.
- 운영체제의 구조:
  - 리눅스 커널은 monolithic 구조: https://makelinux.github.io/kernel/map/
    - MS-DOS 방식은 심플하지만 유지보수가 어려움. 레이어드는 유지보수 쉽지만 성능 문제.
    - 리눅스 OS의 실체는 모듈끼리 강하게 커플링되어 있는 하나의 소프트웨어 커널(kernel).
    - 성능 이점이 있지만, 레이어드보다는 유지보수가 어렵고, 보안과 안정성 측면에서 문제가 있음.
  - 그 대안이 마이크로커널:
    - 커널에는 진짜 핵심적인 것만 남기고 유저 공간에 위임. 확장 쉽고, 포팅 쉽고, 보안도 향상.
    - 다만 유저 공간과 커널 공간 통신으로 성능 오버헤드가 발생함.
    - Tanenbaum-Tovalds debase: 토발즈가 리눅스 만들고 소개하는 글을 썼는데, 타넨바움이 "요즘 세상에 무슨 모놀리식이냐, 마이크로커널이 짱이다"라면서 까는 바람에 키배가 일어남. (https://www.oreilly.com/openbook/opensources/book/appa.html)
  - 요즘 시스템은 어떤 하나의 구조라고 말하기 어려움. 하이브리드.

## Processes

- 지금까지 오버뷰 얘기만 했음. 오늘부터는 실제 운영체제 얘기를 하겠습니다.
- 프로세스는 실행된 프로그램의 인스턴스:
  - 메모리에 로드되어 활성화되어있는 동적인 엔티티.
  - 프로그램은 디스크에 저장된 정적인 엔티티.
- 각 프로세스는 메모리에서 자기만의 주소 공간을 갖는다: code, data, heap, stack.
- 프로세스의 상태: new, ready, running, wait, terminated.
- `pid_t fork(void)`:
  - 루트에 init 프로세스가 있는데, 여기에 자식 프로세스를 만드는 것. 결국 하나의 트리를 이루게 됨.
  - 새 프로세스를 만드려면 당연히 커널 모드에서 해야. 따라서 시스템 콜(`fork`)을 사용해야 한다.
  - 어떤 프로세스에서 `fork()`를 하면 동일한 프로세스가 만들어짐.
  - 프로세스가 제대로 만들어지면 부모에게는 자식 프로세스의 PID를 반환, 자식에게는 0을 반환.
    - `pid_t getpid(void)`: 자신의 (진짜) PID.
    - `pid_t getppid(void)`: 부모의 PID.
  - 자식 프로세스는 `fork` 직후의 인스트럭션을 실행한다.
  - `fork`하는 시점의 메모리 섹션을 그대로 복제하므로, 변수도 `fork` 시점의 값을 갖는다.
  - 부모 프로세스와 자식 프로세스는 독립적임. 자식은 자식의 인생을 살아야 해요.
- `exec` family:
  - 현재 프로세스의 이미지를 새 프로세스 이미지로 교체.
  - 현재 주소 공간을 날리고 새로운 내용을 채운다. `exec("vi")`하면 vi를 실행하는 프로세스가 됨.
  - 여러분이 탐색기를 띄웠어요. 탐색기에서 파워포인트를 더블클릭하면 탐색기가 운영체제한테 `fork`를 날리죠. 그러면 탐색기 프로세스가 하나 더 만들어집니다. 근데 파워포인트를 실행해야하니 `exec`로 스스로를 교체.
- `void exit(int status)`:
  - 프로세스를 삭제한다. 프로세스의 반환 값이 부모 프로세스에게 전달됨.
  - `pid_t wait(int *wstatus)`: 부모 프로세스는 `wait` 시스템 콜을 통해 자식의 반환 값을 기다림.
  - `pid_t waitpid(pid_t pid, int* status, int options)`: 특정 자식을 기다림.
  - `void abort(void)`: 특정 프로세스와 그 부모까지 삭제.
  - 좀비 프로세스:
    - 자식이 삭제됐는데 부모 프로세스가 `wait`를 하지 않는다면?
    - 자식의 반환 값과 PID가 남음. 따라서 종료되었지만 삭제되지는 않은 좀비가 됨.
  - 고아 프로세스:
    - 부모가 삭제된 자식 프로세스.
    - 고아 프로세스를 방지하려면:
      - 부모가 삭제될 때 그 자식도 삭제해는 cascading termination.
      - 아니면 다른 프로세스의 자식으로 만드는 reparenting. 어떤 프로세스의 자식으로 만들 것인가?
        - 옛날 시스템 중에는 부모의 부모가 입양하는 경우도 있었음.
        - 리눅스는 `init` 프로세스의 자식으로 만든다. `init`은 주기적으로 `wait`을 호출해 자식을 정리.
- 프로세스의 구현:
  - 각 프로세스는 Process Control Blcok(PCB)로 표현된다.
  - 프로세스에 대한 모든 정보가 PCB에 담겨있음.
  - 상태, PC(Program Counter), PID, PPID, 레지스터, 메모리 제한, CPU 스케줄링 정보 등.
  - 리눅스에서 프로세스는 `task_struct`로 구현된다.
- IPC(Inter-Process Communication):
  - 하나의 프로그램을 여러 프로세스로 만드는게 굉장히 흔한 모델.
  - 프로세스끼리 통신을 해야 하는데...
  - 공유 메모리(shared memory):
    - 프로세스가 운영체제에게 명시적으로 공유 메모리를 요청할 수 있음: `shm_open`
    - 운영체제가 공유 메모리를 제공한 뒤에는 신경쓰지 않아도 됨.
    - 하지만 관리가 안 된다. 각종 동시성 문제가 일어남.
  - 메시지 패싱(message passing):
    - 택배. `send`, `receive`를 이용해서 프로세스간 메시지 교환을 할 수 있음.
    - 운영체제가 다 알아서 해준다. 마이크로커널이 메시지 패싱을 적극 활용. 분산환경에 좋음.
  - 시그널:
    - 강아지가 시그널을 날려요(?)
    - 프로세스에게 이벤트를 알리는 IPC 매커니즘. 동기적일수도 있고, 비동기적일수도 있음.
    - 소프트웨어 인터럽트라고 생각할수도. 시그널 핸들러가 시그널을 처리한다.
    - `sigaction`으로 어떤 시그널을 받았을 때 어떤 행동을 하라고 정의할 수 있음.
    - 시그널 핸들러도 PCB에 있음. `fork` 어떤 시그널은 복사가 되지만, 어떤 시그널은 안 됨.
  - Remote Procedure Call(RPC):
    - 로컬 기기에서만 IPC를 할 수 있을까? RPC로 원격 프로시저를 호출할 수도 있음.
    - 실제로는 stub을 사용하고, 운영체제의 RPC 레이어에서 통신을 처리해준다.
    - XDR: 범용적인 데이터 표현 형식. 시스템마다 엔디언이 다르기 때문에 RPC 데이터를 XDR로 표현.
  - 파이프:
    - 파이프로 다른 프로세스에 데이터를 밀어넣을 수 있음. 초기 UNIX 시스템의 IPC 매커니즘 중 하나.
    - 데이터가 단방향(unidirectional) 또는 양방향(bidirectional)로 흐를 수 있음.
    - 양방향 파이프에서 읽기/쓰기가 동시에 된다면 full-duplex, 그렇지 않다면 half-duplex.
      - 빨대는 마실수도 있고 뱉을 수도 있으니 양방향이죠. 하지만 마시는 동시에 불 수는 없으므로 half-duplex.
    - Ordinary pipe:
      - 부모-자식 관계에서만 통신 가능한 양방향 파이프.
      - 파일 디스크립터에 따라 읽기 파이프와 쓰기 파이프가 구분됨:
        - `pipe[1]`에 쓴 값을 `pipe[0]`에서 읽을 수 있음. 프로세스 하나에서만 쓰면 그냥 버퍼같겠지.
        - 파이프를 만들고 포크해야 재밌어짐. 파일 디스크립터를 포함해 부모의 컨텍스트가 복제된다.
        - 따라서 자식이 `pipe[1]`에 값을 쓰면 부모가 `pipe[0]`에서 읽을 수 있다. 물론 그 반대도 가능.
    - Named pipe:
      - 부모-자식 관계를 필요로하지 않는 양방향 파이프.
      - 이름이 붙여져 있기 때문에 어떤 프로세스든 파이프를 사용할 수 있음.

## Threads

- 프로세스 하나만 쓴다면 멀티코어의 이점을 누릴 수 없음.
  - 여러 프로세스를 만든다 해도, IPC하는 애플리케이션 작성이 쉽지 않음.
  - 프로세스 생성과 커뮤니케이션, 컨텍스트 스위칭에 비용이 많이 든다.
  - 더 효율적인 방법으로 동시성을 제고할 수 있을까?
- 프로그램의 실행 흐름을 따라 그려보면 하나의 실을 그리게 될 것.
  - 스레드는 실타래입니다. 만약 실타래가 여러 개가 된다면?
  - 프로세스의 실행 상태를 분리해낸다면 어떨까?
- 각 스레드는 주소 공간을 공유한다
  - 스레드가 서로 공유하는 것: 코드, 전역변수, 힙, 파일
  - 각자에 속한 것: 스레드 ID, PC와 SP를 비롯한 레지스터, 스택
- 한 프로세스는 여러 스레드를 가질 수 있고, 스레드는 하나의 프로세스에 종속됨.
- 멀티 스레딩의 장점:
  - 멀티 코어 아키텍처의 장점을 살릴 수 있다.
  - 멀티 프로세스에 비해 리소스가 덜 든다. IPC가 필요없고 그냥 주소 공간에 접근하면 됨.
  - 여러 스레드가 주소 공간을 공유하기 때문에 리소스 공유가 투명해짐.
  - 더 많은 I/O 연산을 처리할 수 있고, 더 많은 동시성 이벤트에 응답할 수 있음. (e.g., 웹 서버)
- 동시성(concurrency) vs 병렬성(parallelism):
  - 님들이 과제1을 풀고, 같은 시각에 친구가 과제2를 풀어주면 병렬적으로 하는거죠.
  - 님들이 과제1을 풀다가 과제2를 조금 풀고, 과제3을 풀고, 다시 과제1을 푸는게 동시성.
  - 사실 병렬성이 있으면 동시성도 가질 수 있겠죠. 동시성이 상위개념임.
  - 데이터 병렬성: 하나의 데이터셋을 쪼개서 같은 연산을 병렬적으로 수행.
  - 태스크 병렬성: 서로 다른 태스크를 병렬적으로 수행.
- 암달의 법칙:
  - 프로그램은 병렬처리 가능한 부분과 불가능한 순차적인 부분으로 나뉨.
  - 따라 아무리 열심히 병렬화를 해도 더 이상 성능이 향상되지 않는 한계가 있다.
  - 병렬화로 어디까지 향상할 수 있나? $S \le {1 \over S + {(1 - S) / N}}$
    - $S$는 순차적인 부분, $1 - S$는 병렬적인 부분. $N$은 코어수.
    - 코어가 무한히 많으면: $1 \over S$. 어쩔 수 없다.
- 멀티스레딩 모델:
  - 커널 스레드:
    - 운영체제가 직접 관리하는 스레드.
    - 커널 스레드는 운영체제가 프로세서에 태스크를 할당할 때 스케줄링의 단위.
  - 유저 스레드:
    - 유저 레벨 스레드 라이브러리에서 관리되는 스레드.
  - One-to-One 모델:
    - 하나의 커널 스레드가 하나의 유저 스레드에 대응하는 모델.
    - 스레드가 너무 많아지면 스케줄링에 너무 많은 리소스가 드는 문제.
    - 대부분의 운영체제가 커널 스레드의 수를 제한하고 있음.
  - Many-to-One 모델:
    - 하나의 커널 스레드 위에 여러 유저 스레드를 올리는 모델.
    - 유저 스레드간 컨텍스트 스위치가 가볍고 빠름. One-to-One 모델의 문제를 해결.
    - 스케줄링 단위는 커널 스레드이므로, 멀티코어 환경에서 의도한대로 유저 스레드가 병렬처리되지 않을수도.
    - 유저 스레드 중 하나가 블로킹되면 다른 스레드가 블로킹될수도.
  - Many-to-Many 모델:
    - 여러 커널 스레드가 여러 유저 스레드에 대응하는 모델.
    - Two-level 모델: 특정 유저 스레드만 커널 스레드에 일대일 대응하고, 나머지는 M:M.
    - 현실적으로 많이 쓰이지는 않음.
- 스레드 라이브러리:
  - POSIX를 잘 지키는 운영체제라면 pthread (POSIX thread)가 있다.
  - 스레드 생성과 동기화를 위한 POSIX 표준(IEEE 1003.1c)
- 암묵적 스레딩:
  - 실제로 멀티스레드 프로그래밍을 하는건 어려운 일임.
    - 물론 성능이 향상되고, 스레드를 잘 사용하는건 중요함. 하지만 인간은 멀티태스킹이 안 되는 동물.
    - 하이레벨에만 신경쓰고 싶다면 다른 방법이 필요. 암묵적 스레딩은 스레드의 생성과 반납을 추상화.
  - 스레드 풀:
    - 풀에 미리 스레드를 만들어두고, 필요할 때 풀에서 하나를 가져와 사용 후 반납.
    - 스레드의 생성과 사용이 분리되는 것. 개발자는 사용만하면 되니 편리하다.
  - Fork Join:
    - 메인 스레드에서 `fork`해서 두 개의 스레드로 분리, 각 스레드의 결과는 `join`으로 병합.
    - divide and conquer 문제를 멀티스레딩으로 해결할 때 유용.
  - OpenMP:
    - C/C++, FORTRAN 컴파일러를 똑똑하게 만들어서 멀티스레딩을 쉽게 만들자.
    - `#pragma omp parallel` 같은 디렉티브를 만나면 코어 개수만큼 스레드를 만들고 알아서 병렬 처리.
    - 공유 메모리 환경으로 병렬 프로그래밍을 지원한다.
- 멀티 스레딩의 문제들:
  - 앞서 배운 `fork`와 `exec`는 싱글코어를 상정한 것.
  - 스레드 하나에서 `fork`하면 어떻게 되나? 스레드도 다 복사되나?
    - In pthread: 호출한 스레드만 복사한다.
    - UNIX: 두 개의 시스템 콜을 제공한다.
      > A call to forkall() replicates in the child process all of the threads in the parent process.
      >
      > A call to fork1() replicates only the calling thread in the child process. (...) In  Solaris 10, a call to fork() is identical to a call to fork1(); only the calling thread is replicated in the child process. This is the POSIX-specified behavior for fork().
      - `forkall`: 부모의 모든 스레드를 자식으로 복사한다. (강의에서는 `fork`로 소개함.)
      - `fork`, `fork1`: 호출한 스레드만 복사한다.
  - `exec`는 멀티스레딩이어도 상관없죠. 어떤 스레드 하나가 `exec`하면 그냥 프로세스의 모든 스레드가 죽음.
- 시그널 핸들링:
  - 시그널이 오면 누가 받아야 하나? 시그널을 어떤 스레드가 받느냐에 따라 동작이 달라질거임.
  - 스레드마다 받을 수 있는 시그널을 명시하기. 명시하지 않으면 아무 스레드에 시그널이 간다.
- 스레드 삭제:
  - 한 스레드에서 다른 스레드를 죽이려면? 특정 스레드를 삭제하는 API가 있음.
  - Deferred cancellation:
    - 스레드를 삭제하긴 하는데, 그 스레드가 죽기전에 뭘하고 있었는지 알고싶다.
    - 즉지 죽지 않고 cancellation point에 도달할 때까지 기다리고 죽는다.
  - Asynchronous cancellation: 대상 스레드를 즉시 삭제한다.
- Thraed-Local Storage(TLS):
  - TLS 타입의 변수를 만들 수 있다.
    - 전역변수처럼 여러 스레드에서 접근할 수 있음.
    - 지역변수처럼 스레드에 종속되어 자체적인 값을 갖는다.
    - 특정 스레드에서 TLS 변수에 값을 써도 그 스레드에서만 변경된다.
  - TLS를 쓰면 동기화 오버헤드를 줄일 수 있다:
    ```diff
    for (i = 0; i < 10; i++) {
    -   LOCK();
    -   sum_global = sum_global + i
    -   UNLOCK();
        sum_tls = sum_tls + i;
    }

    + LOCK();
    + sum_global = sum_tls;
    + UNLOCK();
    ```
  - `errno` 값을 다룰 때도 유용하다:
    - 스레드 하나가 에러나서 `errno`를 `-1`로 설정, 이어서 들어온 다른 스레드가 `errno`를 `0`으로 덮는 문제.
    - `errno`를 TLS로 만들면 문제를 해결할 수 있음.
- 리눅스의 스레드:
  - 사실 프로세스도, 스레드도 그냥 `task_struct`로 구현됨.
    - 스레드는 그저 같은 주소 공간을 공유하는 `task_struct`.
    - 주소 공간이 다르다면 다른 프로세스.
  - `clone`:
    > clone() creates a new process, in a manner similar to fork(2). (...) The main use of clone() is to implement threads: multiple threads of control in a program that run concurrently in a shared memory space.
    - 실행 컨텍스트를 복제해서 새로운 `task_struct`를 만든다.
    - 주소 공간이 같은 `task_struct`를 만들 수 있다. 즉, 스레드를 만드는 것.
