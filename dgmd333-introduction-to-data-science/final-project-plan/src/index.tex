\maketitle

\section{주제}

\textbf{Transformer 기반 모델과 DLinear 모델의 장기 시계열 예측 성능 비교}: 장기 시계열 예측(Long-term Time Series Forecasting, LTSF)을 위한 Transformer 기반 모델 Informer\cite{zhou2021}와 선형 모델 DLinear\cite{zeng2022}의 예측 성능을 비교 분석해 더 이상 시계열 예측에 Transformer 기반 모델이 최선의 선택이 아닌지 확인해 본다.

\section{배경}

지난 수년간 시계열 예측 모델은 ARIMA와 같은 전통적인 통계학 기반 모델부터 LSTM, GRU 등 RNN 기반 모델로 발전해 왔다. 최근에는 Transformer 모델이 자연어 처리 뿐만 아니라 시계열 예측에도 좋은 성과를 내어 Informer, FEDformer, Pyraformer 등 Transformer 모델을 기반으로 다양한 시계열 예측 모델이 광범위하게 연구되고 있다.

특히 2021년 AAAI Outstanding paper로 선정된 Informer 모델은 단기 시계열 예측에만 성과를 보인 기존 모델들의 한계를 넘어 장기 시계열 예측을 높은 성능으로 달성한 기념비적 모델이라고 할 수 있다. 이후 성능을 개선한 Pyraformer\cite{liu2022}, FEDformer\cite{zhou2022} 등 다양한 Tranformer 기반 모델이 연구되었다. 한편 DLinear 모델은 시계열 예측에서 Transformer 기반 모델의 적절성에 관한 의문를 제기한다. DLinear 모델은 매우 단순한 선형 모델로 높은 성능을 달성했고, 이를 통해 Transformer 기반 모델에 대한 본질적인 질문을 던져 주목 받았다.

\section{방법 및 목적}

ETTh1(Electricity Transformer Temperature)\footnote{2016년 7월부터 2018년 7월까지 측정된 중국의 전기 변압기 온도에 대한 1시간 단위 시계열 데이터. 여기서 예측하고자 하는 속성은 오일 온도이다. 오일 온도는 변압기의 상태에 따라 변화하며, 특히 전기 사용량이 많아지는 시기에 온도가 상승한다. 오일 온도가 너무 높으면 변압기가 손상되어 대규모 정전 사태를 야기할 수 있기 때문에 변압기의 오일 온도가 안전한 수준일지 예측하는 것은 중요한 문제다.} 데이터셋에 대하여 Informer 모델과 Pyraformer, FEDformer, DLinear 모델의 예측 성능을 비교 분석할 것이다. ETTh1 데이터셋은 2016년 7월부터 2018년 7월까지 2년간 측정된 전기 변압기 온도에 대한 시계열 데이터로, 총 4개의 모델이 모두 각자의 연구에서 성능 측정을 위해 ETTh1을 공통으로 사용했다. DLinear 모델을 소개한 A. Zeng은 Informer를 비롯한 Transformer 기반 모델들에 비해 DLinear가 더 높은 성능을 보인다고 주장한다. 이 프로젝트에서도 ETTh1 데이터셋에 대해 결과를 재현함으로써 실제로 Transformer 기반 모델이 더 이상 장기 시계열 예측에 사용할 수 있는 최선의 모델이 아닌지 확인해보고자 한다.

차후 가능하다면 논문에서 제시되지 않은 별도 데이터셋에 대해서도 성능 측정을 수행할 것이다. 이는 예측 모델이 임의의 데이터셋에도 유의미한 성능을 달성하는지 확인해보고, 프로덕션 수준에서 활용할 수 있을지 확인하기 위함이다.

\begin{thebibliography}{9}
  \bibitem[1]{zhou2021} H. Zhou et al., ``Informer: Beyond Efficient Transformer for Long Sequence Time-Series Forecasting'', AAAI, <https://arxiv.org/pdf/2012.07436>, Mar 2021.
  \bibitem[2]{zeng2022} A. Zeng et al., ``Are Transformers Effective for Time Series Forecasting?'', arXiv:2205.13504, <https://arxiv.org/pdf/2205.13504>, Aug 2022.
  \bibitem[3]{liu2022} S. Liu et al., ``Pyraformer: Low-complexity Pyramidal Attention for Long-range Time Series Modeling and Forecasting'', ICLR, <https://openreview.net/pdf?id=0EXmFzUn5I>, April 2022.
  \bibitem[4]{zhou2022} T. Zhou et al., ``FEDformer: Frequency Enhanced Decomposed Transformer for Long-term Series Forecasting'', ICML, <https://arxiv.org/pdf/2201.12740>, July 2022.
\end{thebibliography}
